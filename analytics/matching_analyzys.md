# Исследование подходов к алгоритму мэтчинга лидов

## Введение

Задача алгоритма мэтчинга — находить пары между лидами: клиентами, которые ищут квартиру и теми, кто её продаёт.  
Цель — сделать быстрый и понятный алгоритм ранжирования вариантов по парам: агент должен сразу видеть, какие варианты подходят его клиенту **(в идеале знать почему)**.

Основные требования:
- простота реализации и поддержки (без сложного ML);
- быстрая работа (желательно < 1 с);
- возможность расширения, если появятся новые данные и функции;
- работа на объёме до ~1000 лидов.

---

## Структура данных

Каждый лид содержит:
- основные параметры: `type` (buy/sell), `city`, `district`, `coordinates`, `property_type`, `rooms`, `price`, `budget_min/max`, `mortgage_allowed`, `deal_format`, `market_type`, `term`, `commission_offer`, `renovation`;
- `description` — свободный текст, где агент может писать пожелания (например: «рядом парк», «для семьи», «в пешей доступности метро»).

Для MVP этого набора достаточно.  
Позже можно для лидов-клиентов добавить поле с отдельными **пожеланиями по инфраструктуре** (например, галочки или теги — «рядом парк», «рядом школа»). Эти данные можно будет сверять с реальными инфрастуктурными объектами на карте около объекта: есть ли действительно парк, школа и т.д. рядом с адресом.

---

## Подходы к мэтчингу

### 1. Жёсткие фильтры

Первый и самый надёжный этап — отсеивание по понятным полям:
- город и район;
- тип недвижимости;
- комнатность (±1);
- диапазон бюджета или цены;
- ипотека (если задана);
- радиус по координатам.
- Политика риелтора по ипотеке

Так мы быстро убираем явно неподходящие варианты.  
Этот этап выполняется в базе данных SQL-запросом.
При этом для разных ситуаций и риелторов необходима возможность задавать коэффициент мягкости для разных параметров (exmpl. можно подвинуться по стоимости из-за срочности сделки) 

---

### 2. Семантическое сравнение (эмбеддинги)

Для поля `description` использовать **эмбеддинговую модель**.  
Она превращает текст в числовой вектор (например, длиной 1536 чисел для ).  
Два похожих текста будут иметь близкие векторы.  
Чтобы понять, насколько тексты похожи, используется **косинусное сходство** — это число от -1 до 1, где 1 значит, что тексты почти одинаковы по смыслу.

Пример:

“рядом метро” и “в пешей доступности от станции метро” → 0.9

“рядом метро” и “тихая улица” → 0.3


### Модели для эмбеддингов (анализ вариантов)

| Вариант | Пример модели | Язык | Где работает | Плюсы | Минусы |
|----------|----------------|-------|----------------|--------|---------|
| **OpenAI Embeddings** | `text-embedding-3-small`, `text-embedding-3-large` | Мультиязычный (включая русский) | SaaS (через API) | Высокое качество, простая интеграция | Стоимость, внешние вызовы |
| **Cohere Embed** | `embed-multilingual-v3` | Мультиязычный | SaaS | Хорошая поддержка русского | Зависимость от внешнего сервиса |
| **Mistral/LaBSE** | `sentence-transformers/LaBSE` | Мультиязычный | Локально | Бесплатно, офлайн | Требует больше ресурсов |
| **RuBERT / SBERT (HuggingFace)** | `ai-forever/sbert_large_nlu_ru` | Русский | Локально | Оптимален для русского | Нужно развернуть модель на сервере |

Для MVP лучше использовать **OpenAI Embeddings (text-embedding-3-small)** — быстро, не требует инфраструктуры и даёт хорошие результаты на русском языке.  
Позже можно перейти на локальную модель SBERT или LaBSE, если будет важна приватность и офлайн-работа.

---

## Варианты реализации семантической части

### Вариант 1. Расчёт сходства на месте (онлайн)

1. При запросе мэтчинга берётся текущий лид.
2. Из базы достаются векторы кандидатов противоположного типа.
3. Для каждого считается косинусное сходство.
4. Результаты сортируются и возвращаются клиенту.

**Плюсы:**
- не нужно хранить заранее рассчитанные пары;
- всегда актуальные данные.

**Минусы:**
- при большом количестве объектов может быть медленно;
- потребуется оптимизация запросов или использование векторного индекса (pgvector).

---

### Вариант 2. Предрасчёт сходств (офлайн-кеш)

1. При добавлении или обновлении лида считается его вектор.
2. Система сравнивает его со всеми противоположными лидами.
3. Сохраняет top-N (например, 200) лучших совпадений в таблицу `precomputed_matches`.

Таким образом, при запросе мэтчинга система просто отдаёт заранее подготовленный список.

**Плюсы:**
- мгновенный отклик (всё уже посчитано);
- снижает нагрузку на базу при поиске.

**Минусы:**
- требуется дополнительный фоновый процесс, который обновляет кеш;
- данные немного устаревают между пересчётами.

Для MVP можно реализовать именно этот вариант — он проще и обеспечивает стабильную скорость.

---

### Вариант 3. Обучение ML-модели
Когда накопятся данные — например, лайки агентов (какие варианты они отметили как удачные), можно добавить **обучаемую модель**.  
Она будет использовать признаки:
- совпадение цены (`price_score`);
- расстояние (`geo_distance`);
- совпадение описания (`text_similarity`);
- комиссия, тип рынка, ипотека и т.д.;
- предыдущие лайки данного агента.

Модель можно обучить предсказывать вероятность того, что агент поставит «лайк» объекту.  
Подойдут простые модели: **Logistic Regression**, **XGBoost**, **LightGBM**.  
Обучение можно сделать на парных примерах: «понравилось / не понравилось».

**Плюсы:** более точный и персонализированный мэтчинг.  
**Минусы:** нужны данные (лайки, история), время на настройку и обучение.

Для MVP этот этап не нужен — но архитектура должна предусматривать возможность добавить модель позже, используя сохранённые эмбеддинги и признаки.

---

## Идея по инфраструктурным пожеланиям (не для MVP)

Если добавить отдельное поле с пожеланиями клиента (например, чекбоксы: «рядом школа», «рядом парк», «рядом метро»), можно расширить алгоритм:

1. При загрузке объекта система сохраняет его координаты.
2. По сторонним картам (например, OSM) проверяется наличие соответствующих объектов поблизости.
3. Для мэтчинга добавляется дополнительный коэффициент, показывающий, насколько объект соответствует запросу по инфраструктуре.

Пример:
- Покупатель ищет «рядом парк и школа».
- Продавец выставил объект, и по картам видно, что парк в 300 м, школа в 600 м.
- Система повышает итоговый скоринг по этим признакам.

Это направление можно реализовать после MVP, когда основная логика мэтчинга будет стабильна.

---

## Предлагаемое решение для MVP

Для первой версии:
1. Используем **жёсткие фильтры** для быстрого отбора кандидатов.
2. Применяем **эмбеддинги** для сравнения описаний по смыслу.
3. Храним эмбеддинги в Postgres с расширением **pgvector**.
4. Для ускорения — рассчитываем сходства заранее и сохраняем в таблицу `precomputed_matches`.

Формула для итогового скоринга:

score = 0.4 * price_score +
0.2 * geo_score +
0.3 * text_similarity +
0.1 * rooms_match

Такой подход прост в реализации, быстро работает на объёмах MVP и даёт реалистичные результаты без сложных моделей.

---

## Дальнейшее развитие

| Этап | Цель | Что добавляется |
|------|------|-----------------|
| MVP | Основной мэтчинг (фильтры + эмбеддинги) | Быстро и просто |
| V2 | Выделение тегов из описаний | Лучшая семантика |
| V3 | Добавление пожеланий по инфраструктуре | Учёт геообъектов |
| V4 | ML-модель на лайках | Персонализация |

---

# Итоговое решение после 2 раундов обсуждения с заказчиком

После обсуждения с заказчиком и командой было решено на первом этапе реализации начать с алгоритма метчинга на жестких фильтрах:
- Убираем поле description
- Заменяем его на набор возможных-тегов ("рядом парк", "рядом школа", "зеленый район", ...)
- Алгоритм работает, сравнивая жестко выставленные параметры и наборы тегов, применяя к каждому сравнению коэффициент важности.
- По поводу онлайн/оффлайн подсчёта, в рамках условий проекта предлагаю реализовывать оффлайн ранжирование. При добавлении/изменении объектов для них запускается задача подсчитать пары. 

### Причины решения
- Желание в итоге прийти к варианту с **голосовым набором объектов** риелторами, которое не соответсвует предложенному варианту
- Упрощение алгоритма в рамках mvp
- Неясность в взаимодействии с сторонними сервисами построения эмбеддингов